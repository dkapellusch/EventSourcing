
docker run --name ksql-cli --network host -it confluentinc/ksqldb-cli ksql http://0.0.0.0:8088
docker start ksql-cli
docker exec -it eventsourcing_ksql-cli_1 ksql http://KSQL:8088

SET 'auto.offset.reset'='earliest';
SET 'auto.offset.reset'='latest';

Vehicles
_________________________________________________________________________________________________________

Create stream Vehicles (Vin string, Make string, Model string, LocationCode string) WITH (KAFKA_TOPIC='Vehicles', VALUE_FORMAT='json');

CREATE TABLE vehicles_all AS SELECT vin , Collect_List(locationCode) AS locationCode, Collect_List(make) as make, Collect_List(model) as model FROM vehicles GROUP BY vin;
CREATE TABLE vehicles_table AS SELECT vin , locationCode, make, model from vehicles;

Create Table vehicles_count AS SELECT 1 AS Counter FROM vehicles_all;

Locks 
_________________________________________________________________________________________________________

Create stream Locks (ResourceId string, LockHolderId string, LockId string, ResourceType string, Expiry string) WITH (KAFKA_TOPIC = 'Locks', VALUE_FORMAT = 'json');

create stream EnrichedLocks as select ResourceId,LockHolderId,LockId,ResourceType,Expiry, STRINGTOTimeStamp(Expiry,'yyyy-MM-dd''T''HH:mm:ss.SSSSSS''Z''','UTC') <= UNIX_TIMESTAMP() as Inactive from Locks;

create stream InactiveLocks as select * from EnrichedLocks where Inactive = true;
create stream ActiveLocks as select * from EnrichedLocks where Inactive = false ;

create table InactiveLocks_By_LockId as select collect_set(RESOURCEID) as RESOURCEID, collect_set(LOCKHOLDERID) as LOCKHOLDERID, collect_set(RESOURCETYPE) as RESOURCETYPE , lockId, count(lockId) as lockCount, collect_set(expiry) as expiry, collect_set(Inactive) as Inactive from InactiveLocks group by lockId;
create table InactiveLocks_By_ResourceId as select RESOURCEID, count(RESOURCEID) as lockedCount, collect_set(LOCKHOLDERID) as LOCKHOLDERID, collect_set(RESOURCETYPE) as RESOURCETYPE , collect_set(lockId) as lockId, collect_set(expiry) as expiry, collect_set(Inactive) as Inactive from InactiveLocks group by RESOURCEID;

create table ActiveLocks_By_LockId as select collect_set(RESOURCEID) as RESOURCEID, collect_set(LOCKHOLDERID) as LOCKHOLDERID, collect_set(RESOURCETYPE) as RESOURCETYPE , lockId, count(lockId) as lockCount, collect_set(expiry) as expiry, collect_set(Inactive) as Inactive from ActiveLocks group by lockId;
create table ActiveLocks_By_ResourceId as select RESOURCEID, count(RESOURCEID) as lockedCount, collect_set(LOCKHOLDERID) as LOCKHOLDERID, collect_set(RESOURCETYPE) as RESOURCETYPE , collect_set(lockId) as lockId, collect_set(expiry) as expiry, collect_set(Inactive) as Inactive from ActiveLocks group by RESOURCEID;

Notifications
_________________________________________________________________________________________________________


Create stream Notifications (NotificationId string, Category string, NotificationTime bigint, Data string) WITH (KAFKA_TOPIC = 'Notifications', VALUE_FORMAT = 'json');
Create stream NotificationTicks as Select *, 1 as JoinMe from Notifications where Category = 'Ticks' emit changes;
Create stream Events as Select *, 1 as JoinMe from Notifications where not Category = 'Ticks' emit changes;

Create stream ReadyNotifications as Select 
Events.NotificationId as NotificationId, Events.Category as Category,
Events.NotificationTime as NotificationTime, Events.Data as data
from Events left join NotificationTicks within 1 hour on Events.JoinMe=NotificationTicks.JoinMe
where Events.NotificationTime <= UNIX_TIMESTAMP() and
      Events.NotificationTime + 999 >= UNIX_TIMESTAMP()
emit changes;


create table Notifications_By_NotificationId as 
select 
 NotificationId,
 count(NotificationId) as notificationCount,
 collect_set(Category) as Category,
 collect_set(NotificationTime) as NotificationTime,
 collect_set(Data) as Data 
from ReadyNotifications group by NotificationId;

create table PendingNotifications_By_NotificationId as 
select 
 NotificationId,
 count(NotificationId) as notificationCount,
 collect_set(Category) as Category,
 collect_set(NotificationTime) as NotificationTime,
 collect_set(Data) as Data 
from Events group by NotificationId;


create stream ticks (joinme int) WITH (KAFKA_TOPIC = 'ticks', VALUE_FORMAT = 'json', partitions=1, replicas=1);

Select 
Events.NotificationId as NotificationId, Events.Category as Category,
Events.NotificationTime as NotificationTime, Events.Data as data
from Events left join ticks within 1 hour on Events.JoinMe=ticks.JoinMe
where Events.NotificationTime <= UNIX_TIMESTAMP() and
      Events.NotificationTime + 100 >= UNIX_TIMESTAMP()
emit changes;


create stream ReadyNotifications as Select 
Events.NotificationId as NotificationId, Events.Category as Category,
Events.NotificationTime as NotificationTime, Events.Data as data
from ticks left join Events within 1 hour on Events.JoinMe=ticks.JoinMe
where Events.NotificationTime <= UNIX_TIMESTAMP() and
    Events.NotificationTime + 1000 >= UNIX_TIMESTAMP()
emit changes;
_________________________________________________________________________________________________________

IceBox
_________________________________________________________________________________________________________

insert into locks 
select vin, Expiry, lockId, STRINGTOTimeStamp(expiry,'yyyy-MM-dd''T''HH:mm:ss.SSSSSS''Z''','UTC') <= UNIX_TIMESTAMP() as expired
 from locks WINDOW TUMBLING (SIZE 60 Seconds) 
 where expired is null or expired = false;

Create Table lock_status as
Select
  collect_set(vin) as vin,
  lockId,
  collect_set(expiry) as expiration,
  collect_set(expired) as expired
from locks 
  group by lockId
emit changes;

Create Table expired_locks as
Select
  collect_set(vin) as vin,
  lockId,
  collect_set(expiry) as expiration
from locks
  where expired
  group by lockId
emit changes;

Create Table lock_changes as
Select
  count(lockId) as evaluationCount,
  lockId,
  collect_set(expiry) as expiration,
  collect_set(expired) as expired
from locks WINDOW HOPPING (SIZE 5 SECONDS, ADVANCE BY 1 SECONDS)
  GROUP BY lockId HAVING COUNT(*) < 2
emit changes;

CREATE STREAM LocksWithRoutingKey AS SELECT vin, expiry, lockId, case when expired is null then false else expired end as expired, 'locks' as RoutingKey FROM locks where (expired is null or expired = false);

Create Stream LockTicks as select 
LocksWithRoutingKey.vin as vin,
LocksWithRoutingKey.expiry as expiry,
LocksWithRoutingKey.lockId as lockId,
STRINGTOTimeStamp(Expiry,'yyyy-MM-dd''T''HH:mm:ss.SSSSSS''Z''','UTC') <= UNIX_TIMESTAMP() as expired
from ticks join LocksWithRoutingKey within 48 hours on ticks.routingkey=LocksWithRoutingKey.routingkey
where ticks.routingkey = 'locks'
emit changes;

Create Stream LockTicks as select 
LocksWithRoutingKey.vin as vin,
LocksWithRoutingKey.expiry as expiry,
LocksWithRoutingKey.lockId as lockId,
STRINGTOTimeStamp(Expiry,'yyyy-MM-dd''T''HH:mm:ss.SSSSSS''Z''','UTC') <= UNIX_TIMESTAMP() as expired
from LocksWithRoutingKey left join ticks within 48 hours on ticks.routingkey=LocksWithRoutingKey.routingkey
where ticks.routingkey = 'locks' and  (LocksWithRoutingKey.expired = false or LocksWithRoutingKey.expired != true or not LocksWithRoutingKey.expired )
emit changes;

insert into locks select vin, Expiry, lockId, true as expired from LockTicks where expired;
create stream ExpiredLocks as select vin, expiry, lockId, true as expired from LockTicks  where expired;
create stream LocksThatExpired as select collect_set(vin), lockId, count(lockId) as count,  collect_set(true) as expired from TickLocks group by lockid where expired = true ;
